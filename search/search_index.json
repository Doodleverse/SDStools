{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SDS Tools","text":"<p>Welcome to SDS tools!</p> <p></p> <p>SDS tools is a comprehensive suite of tools designed for the robust analysis of time series shoreline data. It provides functionalities for filtering outliers, conducting in-depth data analysis, and identifying trends, thereby enabling more accurate and reliable shoreline data interpretation.</p> <p>This website and the code is currently under active development.</p>"},{"location":"#sds-analysispost-processing-scripts-available-for-use","title":"SDS analysis/post-processing scripts available for use","text":"<ol> <li> <p><code>filter_outliers_hampel_spacetime.py</code>: Removes outliers from time series data using the Hampel filter applicable for <code>raw_transect_time_series.csv</code> &amp; <code>tidally_corrected_transect_time_series.csv</code>. This takes a csv file of time (rows) versus transects (columns) and outputs a new csv file in the same format.</p> </li> <li> <p><code>inpaint_spacetime.py</code>: Use this script to fill in the missing values after using the script <code>filter_outliers_hampel_spacetime.py</code> to remove outliers from the time series data. This takes a csv file of time (rows) versus transects (columns) and outputs a new csv file in the same format.</p> </li> <li> <p><code>detrend_relstart_transect_timeseries.py</code>: Use this script to detrend each transect relative to a stable initial value.  This takes a csv file of time (rows) versus transects (columns) and outputs a new csv file in the same format.</p> </li> <li> <p><code>analyze_transects.py</code>: Use this script to statistically analyze data after using the script <code>inpaint_spacetime.py</code> to analyze the time series data. This generates one csv file that contains statistics per transect, and an npz file that contains 2d arrays of linear trend, autocorrelation, etc.  This takes a csv file of time (rows) versus transects (columns) and outputs a new csv file in the same format.</p> </li> <li> <p><code>denoise_inpainted_spacetime.py</code>: Use this script to denoise an inpainted SDS matrix using a Morlet wavelet (experimental). This results in a smoother dataset, but carries out filtering in both space and time.</p> </li> </ol>"},{"location":"#auxiliary-scripts-available-for-use","title":"Auxiliary scripts available for use","text":"<ol> <li> <p><code>download_era5_dataframe_singlelocation.py</code>: Use this script to download a time-series of bulk wave statistics at a single point, using a geoJSON polygon as input</p> </li> <li> <p><code>download_era5_dataframe_grid.py</code>: Use this script to download a time-series of bulk wave statistics over a 2d grid, using a geoJSON polygon as input</p> </li> <li> <p><code>download_topobathymap_geojson.py</code>: Use this script to download a topobathymetric map at approx ~3m resolution, and store as a geoTIFF. Takes geoJSON polygon as input</p> </li> <li> <p><code>download_topobathymap_geotiff.py</code>: Use this script to download a topobathymetric map at approx ~3m resolution, and store as a geoTIFF. Takes geoTIFF, e.g. a CoastSeg image, as input</p> </li> <li> <p><code>make_csv_per_transect_tide_crt.py</code>: Saves the tidally corrected time series for each transect with intersections with the shoreline </p> </li> <li> <p><code>make_csv_per_transect_raw.py</code>: Saves the raw time series for each transect with intersections with the shoreline</p> </li> </ol>"},{"location":"#test-script","title":"Test script","text":"<p><code>test_scripts.sh</code> is a utility script for testing all scripts using example datasets</p>"},{"location":"analyze_transects_guide/","title":"Usage Guide for analyze_transects.py","text":"<p>This script analyzes each transect in a csv file of SDS data and computes a number of statistics for each transect. These statistics summarize a variety of quantities that are outlined below.</p> <p>Each variable in the output CSV file, and their meaning:</p> <ul> <li><code>stationarity</code>: 1=statistically significant stationarity (i.e., a lack of trend. Otherwise, 0). This uses the Augmented Dickey-Fuller test docs here</li> <li><code>autocorr_min</code>: minimum autocorrelation</li> <li><code>lag_min</code>: lag associated with minimum autocorrelation</li> <li><code>entropy</code>: If this value is high, then the timeseries is probably unpredictable. details here</li> <li><code>linear_trend_slopes</code>: slope of linear fit</li> <li><code>linear_trend_intercepts</code>: intercept of linear fit</li> <li><code>linear_trend_rvalues</code>: correlation of linear fit with underlying data</li> <li><code>linear_trend_pvalues</code>: significance of linear fit (probability of no trend)</li> <li><code>linear_trend_stderr</code>: standard error in estimate of linear trend slope</li> <li><code>linear_trend_intercept_stderr</code>: standard error of linear trend intercept</li> </ul> <p>Each variable in the output NPZ file, and their meaning:</p> <ul> <li><code>trend2d</code>: 2d matrix of shoreline trend (decomposed using the STL technique)</li> <li><code>season2d</code>: 2d matrix of shoreline seasonality (decomposed using the STL technique)</li> <li><code>auto2d</code>: 2d matrix of autocorrelation </li> <li><code>weights2d</code>: 2d matrix of autocorrelation (decomposed using the STL technique)</li> <li><code>cs_transects_vector</code>: vector of transect names</li> <li><code>cs_dates_vector</code>: vector of shoreline dates</li> <li><code>cs_data_matrix_demeaned</code>: the demeaned version of the data used to compute statistics</li> <li><code>df_resampled</code>: the regular-in-time (resampled) version of the data used to compute statistics</li> </ul>"},{"location":"analyze_transects_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python analyze_transects.py --help\n</code></pre>"},{"location":"analyze_transects_guide/#command-line-arguments","title":"Command line arguments","text":"<ul> <li><code>-f</code>: Sets the file (csv) to be analyzed</li> </ul> More details The csv format file shoule contain shoreline positions in each cell, with rows as time and columns as transects  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"analyze_transects_guide/#examples","title":"Examples","text":""},{"location":"analyze_transects_guide/#example-1-basic-usage","title":"Example #1: Basic Usage","text":"<p>This example analyzes the <code>transect_time_series_coastsat_nooutliers_inpainted.csv</code> file using the default parameters:</p> <pre><code>python analyze_transects.py -f /path/to/SDStools/example_data/transect_time_series_coastsat_nooutliers_inpainted.csv -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plot is created. This shows the data as a 2d matrix of a) trend in shoreline position, b) seasonal shoreline excursion, and c) autocorrelation as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience:</p> <p></p> <p>This shows the contents of the compressed numpy archive (.npz) file.</p> <p></p>"},{"location":"analyze_transects_guide/#future-work","title":"Future work","text":"<ol> <li>add https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.kpss.html option</li> <li>add https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.levinson_durbin.html for autoregressive test</li> </ol>"},{"location":"denoise_inpainted_spacetime_guide/","title":"Usage Guide for denoise_inpainted_spacetime.py","text":"<p>Use this script to filter values, after using the script <code>inpaint_spacetime.py</code>, by applying a calibrated wavelet denoising to the space-time shoreline data.</p> <p>The script reads a CSV file containing shoreline data and applies a calibrated wavelet filter to the data to filter out unstructured noise. The processed data is saved to a new CSV file, and a comparison plot of the original and filtered data matrices is generated and saved.</p>"},{"location":"denoise_inpainted_spacetime_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python denoise_inpainted_spacetime.py --help\n</code></pre>"},{"location":"denoise_inpainted_spacetime_guide/#command-line-arguments","title":"Command line arguments","text":"<ul> <li><code>-f</code>: Sets the file (csv) to be analyzed</li> </ul> More details The csv format file shoule contain shoreline positions in each cell, with rows as time and columns as transects  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"denoise_inpainted_spacetime_guide/#examples","title":"Examples","text":""},{"location":"denoise_inpainted_spacetime_guide/#example-1-basic-usage","title":"Example #1: Basic Usage","text":"<p>This example filters the values from the <code>transect_time_series_coastsat_inpainted.csv</code> file using the default parameters:</p> <pre><code>python denoise_inpainted_spacetime.py -f \"/path/to/SDStools/example_data/transect_time_series_coastsat_inpainted.csv\" -p 1 \n</code></pre> <p>Here's an example screenshot </p> <p>The (optional) plot is created. This shows the data as a 2d matrix of shoreline positions as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience:</p> <p></p>"},{"location":"detrend_spacetime_guide/","title":"Usage Guide for detrend_relstart_transect_timeseries.py","text":"<p>Use this script to detrend each transect relative to the initial condition. The initial condition is defined by the number, <code>N</code>, or data points to use at the start. Must be 1 or more. Typically this number would be less than 20.</p> <p>The script reads a CSV file containing shoreline data and detrends each based on the mean of the first <code>N</code> data points on that transect. The processed data is saved to a new CSV file, and a comparison plot of the original and filtered data matrices is generated and saved.</p>"},{"location":"detrend_spacetime_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python detrend_relstart_transect_timeseries.py --help\n</code></pre>"},{"location":"detrend_spacetime_guide/#command-line-arguments","title":"Command line arguments","text":"<ul> <li><code>-f</code>: Sets the file (csv) to be analyzed</li> </ul> More details The csv format file should contain shoreline positions in each cell, with rows as time and columns as transects  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"detrend_spacetime_guide/#examples","title":"Examples","text":""},{"location":"detrend_spacetime_guide/#example-1-basic-usage","title":"Example #1: Basic Usage","text":"<p>This example detrends the values from the <code>transect_time_series_coastsat_inpainted.csv</code> file using the default parameters:</p> <pre><code>python detrend_relstart_transect_timeseries.py -f \"/path/to/SDStools/example_data/transect_time_series_coastsat_inpainted.csv\" -p 1 \n</code></pre> <p>Here's an example screenshot </p> <p>The (optional) plot is created. This shows the data as a 2d matrix of shoreline positions as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience:</p> <p></p>"},{"location":"download_topobathy_guide/","title":"Usage Guide for download_topobathymap_geojson.py and download_topobathymap_geotiff.py","text":"<p>This script downloads topobathymetric data using the <code>bathyreq</code> package. Currently only digital elevation model (DEM) data from the NOAA National Centers for Environmental Information (NCEI) database is supported.</p> <p>There are two scripts, one based on defining the spatial extent with a geoJSON file, and the other defines the spatial region using a geoTIFF, for example one downloaded by CoastSeg.</p>"},{"location":"download_topobathy_guide/#need-help","title":"Need Help?","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python download_topobathymap_geojson.py --help\n</code></pre> <p>or </p> <pre><code>python download_topobathymap_geotiff.py --help\n</code></pre>"},{"location":"download_topobathy_guide/#common-command-line-arguments","title":"Common command line arguments","text":"<ul> <li><code>-f</code>: Sets the file that defines spatial extents</li> </ul> More details The file should be geotiff when using `download_topobathymap_geotiff.py` and a geojson polygon when using `download_topobathymap_geojson.py`  <ul> <li><code>-s</code>: Sets the file prefix to use for output data files</li> </ul> More details A string that typically represents the name of the place where the data come from  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"download_topobathy_guide/#examples","title":"Examples","text":""},{"location":"download_topobathy_guide/#example-1-basic-usage-with-geojson","title":"Example #1: Basic Usage with geojson","text":"<p>This example downloads topobathy data according to a geoJSON file</p> <pre><code>python download_topobathymap_geojson.py -s \"LongIsland\" -f \"/path/to/SDStools/example_data/longisland_example.geojson\" -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plot is created. This is not intended to be a publication ready figure. This merely shows the data, as a convenience:</p> <p></p>"},{"location":"download_topobathy_guide/#example-2-basic-usage-with-geotiff","title":"Example #2: Basic Usage with geotiff","text":"<p>This example downloads topobathy data according to a geoTIFF file</p> <pre><code>python download_topobathymap_geotiff.py -s \"Klamath\" -f \"/path/to/SDStools/example_data/2017-10-02-18-57-29_L8_GREATER_KLAMATH_ms.tif\" -p 1 \n</code></pre> <p>The (optional) plot is created. This is not intended to be a publication ready figure. This merely shows the data, as a convenience:</p> <p></p>"},{"location":"download_waves_guide/","title":"Usage Guide for download_era5_dataframe_singlelocation.py and download_era5_dataframe_grid.py","text":"<p>This script downloads wave data from ERA5-reanalysis</p>"},{"location":"download_waves_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python download_era5_dataframe_singlelocation.py --help\n</code></pre> <p>or </p> <pre><code>python download_era5_dataframe_grid.py --help\n</code></pre>"},{"location":"download_waves_guide/#common-command-line-arguments","title":"Common command line arguments","text":"<ul> <li><code>-i</code>: Sets the file prefix to use for output data files</li> </ul> More details A string that typically represents the name of the place where the data come from  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot  <ul> <li> <p><code>-a</code>: start year</p> </li> <li> <p><code>-b</code>: end year</p> </li> </ul>"},{"location":"download_waves_guide/#examples","title":"Examples","text":""},{"location":"download_waves_guide/#example-1-single-point","title":"Example #1: single point","text":"<p>Additional command line arguments:</p> <ul> <li><code>-x</code>: longitude</li> <li><code>-y</code>: latitude</li> <li><code>-w</code>: water depth, either 'deep' or 'intermediate'</li> </ul> More details Intermediate water is defined as water depths where d/L is between 0.05 and 0.5, where d = water depth in meters, and L is wavelength in meters  <p>This example downloads waves at a single point</p> <pre><code>python download_era5_dataframe_singlelocation.py  -i \"my_location\" -a 1984 -b 2023 -x -160.8052  -y 64.446 -w intermediate -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plots created. This is not intended to be a publication ready figures. This merely shows the data, as a convenience:</p> <p></p> <p>slapton_reanalysis-era5-single-levels_joint_and_marginal_distributions_Hs_Tpeak </p>"},{"location":"download_waves_guide/#example-2-grid","title":"Example #2: grid","text":"<p>Additional command line arguments:</p> <ul> <li><code>-f</code>: Sets the file (geojson) to be analyzed</li> </ul> More details The geoJSON format file should contain a polygon  <p>For 2D measurements, at 'my_location', from 1984 to 2023 inclusive, according to a geoJSON file region of interest</p> <pre><code>python download_era5_dataframe_grid.py -i \"my_location\" -a 1984 -b 2023 -f /path/to/your/geoJSON file -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plots created. This is not intended to be a publication ready figures. This merely shows the data, as a convenience:</p> <p></p>"},{"location":"filter_outliers_guide/","title":"Usage Guide for filter_outliers_hampel_spacetime.py","text":"<p>This script removes outliers from time series data produced by CoastSeg using the Hampel filter, which identifies outliers by comparing each data point to the median of a sliding window centered around it. If a data point deviates from the median by more than a specified threshold, it is considered an outlier and can be replaced with the median value. This process helps in cleaning and smoothing time series files, such as <code>raw_transect_time_series.csv</code> &amp; <code>tidally_corrected_transect_time_series.csv</code>, based on user-defined parameters for threshold, iterations, and window size.</p>"},{"location":"filter_outliers_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python filter_outliers_hampel_spacetime.py --help\n</code></pre>"},{"location":"filter_outliers_guide/#command-line-arguments","title":"Command line arguments","text":"<ul> <li><code>-f</code>: Sets the file (csv) to be analyzed</li> </ul> More details The csv format file shoule contain shoreline positions in each cell, with rows as time and columns as transects  <ul> <li><code>-s</code>: Sets the integer threshold for outlier detection. Here it is set to 3.</li> </ul> More details The threshold determines how many standard deviations a data point must deviate from the median within a sliding window to be considered an outlier. If a data point's deviation exceeds this threshold, it is flagged as an outlier and can be replaced by the median value of the window.  <ul> <li><code>-i</code>: Sets the number of iterations for applying the Hampel filter. Here it is set to 5, meaning the filter will be applied for 5 iterations.</li> </ul> More details The number of iterations in the Hampel filter determines how many times the filter is applied to the data. Multiple iterations can enhance the effectiveness of outlier removal by progressively refining the data and eliminating any residual outliers that may not have been detected in earlier passes.  <ul> <li><code>-w</code>: Sets the window size as a percentage of the data length. Here it is set to 20% of the data length.</li> </ul> More details The window size in the Hampel filter specifies the span of data points (as a percentage of the total data length) around each target point that are used to calculate the median and median absolute deviation. This sliding window determines the local context for outlier detection, with a larger window capturing more data points and a smaller window providing a more localized analysis.  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"filter_outliers_guide/#examples","title":"Examples","text":""},{"location":"filter_outliers_guide/#example-1-basic-usage","title":"Example #1: Basic Usage","text":"<p>This example removes the outliers from the <code>raw_transect_time_series.csv</code> file using the default parameters:</p> <pre><code>python filter_outliers_hampel_spacetime.py -f \"/path/to/SDStools/example_data/raw_transect_time_series.csv\" -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plot is created. This shows the data as a 2d matrix of shoreline positions as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience: </p>"},{"location":"filter_outliers_guide/#example-2-custom-parameters","title":"Example #2: Custom Parameters","text":"<p>This removes outliers from the <code>raw_transect_time_series.csv</code> using the following parameters :</p> <pre><code>python filter_outliers_hampel_spacetime.py -f \"/path/to/SDStools/example_data/raw_transect_time_series.csv\" -s 3 -i 5 -w 0.20\n</code></pre> <p>Here's an example screenshot:</p> <p></p> <p>The (optional) plot is created. This shows the data as a 2d matrix of shoreline positions as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience: </p>"},{"location":"inpaint_spacetime_guide/","title":"Usage Guide for inpaint_spacetime.py","text":"<p>Use this script to fill in the missing values after using the script <code>filter_outliers_hampel_spacetime.py</code> to impute (inpaint) missing data from time series data.</p> <p>The script <code>inpaint_spacetime.py</code> reads a CSV file containing shoreline data and applies biharmonic inpainting to fill missing values in the data matrix. The processed data is saved to a new CSV file, and a comparison plot of the original and inpainted data matrices is generated and saved.</p>"},{"location":"inpaint_spacetime_guide/#need-help","title":"Need Help","text":"<p>To view the help documentation for the script, use the following command:</p> <pre><code>python inpaint_spacetime.py --help\n</code></pre>"},{"location":"inpaint_spacetime_guide/#command-line-arguments","title":"Command line arguments","text":"<ul> <li><code>-f</code>: Sets the file (csv) to be analyzed</li> </ul> More details The csv format file shoule contain shoreline positions in each cell, with rows as time and columns as transects  <ul> <li><code>-p</code>: If 1, make a plot</li> </ul> More details A flag to make (or suppress) a plot"},{"location":"inpaint_spacetime_guide/#examples","title":"Examples","text":""},{"location":"inpaint_spacetime_guide/#example-1-basic-usage","title":"Example #1: Basic Usage","text":"<p>This example inpaints the missing values from the <code>raw_transect_time_series_nooutliers.csv</code> file using the default parameters:</p> <pre><code>python inpaint_spacetime.py -f \"/path/to/SDStools/example_data/raw_transect_time_series_nooutliers.csv\" -p 1\n</code></pre> <p>Here's an example screenshot</p> <p></p> <p>The (optional) plot is created. This shows the data as a 2d matrix of shoreline positions as a function of time and transect. This plot is purely for QA/QC purposes and is not intended to be a publication ready figure. This merely shows the data, as a convenience: </p>"},{"location":"install-guide/","title":"How to Install","text":"<p>Currently, SDS_tools runs in the coastseg environment. Follow the CoastSeg installation guide to set up a conda environment with CoastSeg installed then in this activate environment run any of the SDS_tools scripts.</p>"},{"location":"install-guide/#clone","title":"Clone","text":"<p>Clone the github repo</p> <pre><code>git clone --depth 1 https://github.com/Doodleverse/SDStools.git\n</code></pre>"},{"location":"install-guide/#install-additional-dependencies","title":"Install Additional Dependencies","text":"<p>SDS tools differs from CoastSeg in that it uses 3 additional dependencies</p> <ul> <li><code>statsmodels</code>: Provides statistical models and filters, such as the Hampel Filter. See here</li> <li><code>bathyreq</code>: Allows downloading topobathy data using BathyReq</li> <li><code>cdsapi</code>: Enables downloading ERA5 wave data from the CDSAPI</li> </ul> <pre><code>conda activate coastseg\ncd &lt;location SDS_tools installed&gt;\npip install statsmodels bathyreq cdsapi\n</code></pre>"},{"location":"install-guide/#how-to-use-the-scripts","title":"How to Use the Scripts","text":"<p>After installing the dependencies, activate the CoastSeg environment, navigate to the scripts directory within SDS_tools, and run the desired script.</p> <pre><code>conda activate coastseg\ncd &lt;location SDS_tools installed&gt;\ncd scripts\npython &lt;script_name.py&gt;\n</code></pre> <p>Replace  with the name of the script you want to run."}]}